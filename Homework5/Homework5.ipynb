{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5ade700e-1f9a-4268-a809-4f829ce411c8",
   "metadata": {},
   "source": [
    "# Homework 5: Scene-Dependent Image Segmentation\n",
    "\n",
    "The goal of this homework is to implement a model that seperates foreground and background objects for a specific scene.  \n",
    "We will use the highway scene from the Change Detection dataset:  \n",
    "http://jacarini.dinf.usherbrooke.ca/dataset2014#\n",
    "\n",
    "![input image](highway/input/in001600.jpg \"Title\") ![gt image](highway/groundtruth/gt001600.png \"Title\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6fb7169c",
   "metadata": {},
   "source": [
    "The groundtruth images contain 5 labels namely\n",
    "- 0 : Static\n",
    "- 50 : Hard shadow\n",
    "- 85 : Outside region of interest\n",
    "- 170 : Unknown motion (usually around moving objects, due to semi-transparency and motion blur)\n",
    "- 255 : Motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a3d58d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T15:03:07.610471700Z",
     "start_time": "2023-06-28T15:03:07.601473500Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ea8b5923-78bb-48e7-8db6-79b35b79b942",
   "metadata": {},
   "source": [
    "## Task 1: Create a custom (Pytorch) dataset\n",
    "\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
    "You need to create a class that inherets from **from torch.utils.data.Dataset** and implements two methods:\n",
    "- **def \\_\\_len\\_\\_(self)**:  returns the length of the dataset\n",
    "- **def \\_\\_getitem\\_\\_(self, idx)**: given an integer idx returns the data x,y\n",
    "    - x is the image as a float tensor of shape: $(3,H,W)$ \n",
    "    - y is the label image as a mask of shape: $(H,W)$ each pixel should contain the label 0 (background) or 1 (foreground). It is recommended to use the type torch.long\n",
    "    \n",
    "**Tips**:\n",
    "- The first 470 images are not labeled. Just ignore these images. \n",
    "- If possible load all images into memory or evene directly to GPU to increase speed.\n",
    "- You can change the resolution to fit your model or your memory\n",
    "- Add data augmentation to increase the data size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b84fd59b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T15:03:08.159780900Z",
     "start_time": "2023-06-28T15:03:08.146261300Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "def binarize(img):\n",
    "    img = img > 0\n",
    "    bin_img = torch.tensor(img, dtype = torch.long)\n",
    "    return bin_img\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, imgs_dir, targets_dir, transform=None, imgs_to_skip=469):\n",
    "        self.imgs_dir = imgs_dir\n",
    "        self.targets_dir = targets_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        # get a list of the name of the images that are in the directory:\n",
    "        #  - skip first 469 images, because they are labeled\n",
    "        #  - sort it, so we are sure input image matches target\n",
    "        self.img_file_names = list(sorted(os.listdir(imgs_dir)[imgs_to_skip:]))\n",
    "        self.target_file_names = list(sorted(os.listdir(targets_dir)[imgs_to_skip:]))\n",
    "        assert len(self.img_file_names) == len(self.target_file_names) # make sure we have the same number of images and targets\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.target_file_names)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # 1. read input image\n",
    "        img_path = os.path.join(self.imgs_dir, self.img_file_names[idx])\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n",
    "        img_tensor = torch.from_numpy(img)\n",
    "\n",
    "        # 2. read target image\n",
    "        target_path = os.path.join(self.targets_dir, self.target_file_names[idx])\n",
    "        target_img = cv2.imread(target_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        if self.transform:\n",
    "            target_img = self.transform(target_img)\n",
    "        target_tensor = target_img\n",
    "        return img_tensor, target_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd398ae9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T15:03:08.437770700Z",
     "start_time": "2023-06-28T15:03:08.420200500Z"
    }
   },
   "outputs": [],
   "source": [
    "# dataset = CustomImageDataset(imgs_dir='./highway/input', targets_dir='./highway/groundtruth', transform=binarize)\n",
    "# print(f\"Dataset size={len(dataset)}\")\n",
    "# org_img, mask_img = dataset[1220]\n",
    "# plt.imshow(org_img)\n",
    "# plt.show()\n",
    "# plt.imshow(mask_img, cmap=\"gray\")\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0e120eb7-0349-4bb0-b305-23a0f3bb5e26",
   "metadata": {},
   "source": [
    "## Task 2: Create a custom Segmentation Model\n",
    "\n",
    "- input: a batch of images $(B,3,H,W)$ \n",
    "- output: a batch of pixel-wise class predictions $(B,C,H,W)$, where $C=2$\n",
    "\n",
    "Tips:\n",
    "- It is recommended to use a Fully-Convolutional Neural Network, because it flexible to the input and output resolution.\n",
    "- Use Residual Blocks with convolutional layers.\n",
    "- Base your model on established segmentation models:\n",
    "    - U-Net: https://arxiv.org/abs/1505.04597\n",
    "    - Deeplab: https://arxiv.org/abs/1606.00915"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "        self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "class AiaUNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(AiaUNet, self).__init__()\n",
    "\n",
    "        self.inc = (DoubleConv(in_channels, 64))\n",
    "        self.down1 = (Down(64, 128))\n",
    "        self.down2 = (Down(128, 256))\n",
    "        self.up3 = (Up(256, 128))\n",
    "        self.up4 = (Up(128, 64))\n",
    "        self.outc = (OutConv(64, out_channels))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x = self.up3(x3, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        return logits"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T15:03:08.946455400Z",
     "start_time": "2023-06-28T15:03:08.934431300Z"
    }
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a85364b0-7010-4710-9373-94a89db8d7c5",
   "metadata": {},
   "source": [
    "## Task 3: Create a training loop\n",
    "- split data into training and test data, e.g. 80% training data and 20% test data using your custom dataset.\n",
    "- Create a Dataloader for your custom datasets \n",
    "- Define a training loop for a single epoch:\n",
    "    - forward pass\n",
    "    - Loss function, e.g. cross entropy\n",
    "    - optimizer \n",
    "    - backward pass\n",
    "    - logging\n",
    "- Define validation loop:\n",
    "    - forward pass\n",
    "    - extract binary labels, e.g. threshold or argmax for each pixel.\n",
    "    - compute evaluation metrics: Accuracy, Precision, Recall and Intersection over Union for each image"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split data test/train and create dataloader"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size = 984, number of batches in train = 246\n",
      "Test size = 247, number of batches in test = 62\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "dataset = CustomImageDataset(imgs_dir='./highway/input', targets_dir='./highway/groundtruth', transform=binarize)\n",
    "dataset_size = len(dataset)\n",
    "\n",
    "train_size_percentage = 0.8\n",
    "train_size = int(dataset_size * train_size_percentage)\n",
    "test_size = dataset_size - train_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "batch_size = 4 # with 8 or more I get CUDA out of memory :/\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Train size = {len(train_dataset)}, number of batches in train = {len(train_loader)}\")\n",
    "print(f\"Test size = {len(test_dataset)}, number of batches in test = {len(test_loader)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T15:03:09.786156800Z",
     "start_time": "2023-06-28T15:03:09.738809300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define a training loop"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on cuda device\n",
      "Epoch=1\n",
      "\tIteration nr 10: loss=115.27424621582031\n",
      "\tIteration nr 20: loss=147.3333740234375\n",
      "\tIteration nr 30: loss=136.964111328125\n",
      "\tIteration nr 40: loss=139.22616577148438\n",
      "\tIteration nr 50: loss=109.6189956665039\n",
      "\tIteration nr 60: loss=110.09159088134766\n",
      "\tIteration nr 70: loss=92.34272766113281\n",
      "\tIteration nr 80: loss=117.950439453125\n",
      "\tIteration nr 90: loss=111.44789123535156\n",
      "\tIteration nr 100: loss=49.79337692260742\n",
      "\tIteration nr 110: loss=130.32078552246094\n",
      "\tIteration nr 120: loss=124.33794403076172\n",
      "\tIteration nr 130: loss=148.1920166015625\n",
      "\tIteration nr 140: loss=117.60888671875\n",
      "\tIteration nr 150: loss=113.54073333740234\n",
      "\tIteration nr 160: loss=31.070484161376953\n",
      "\tIteration nr 170: loss=86.25753021240234\n",
      "\tIteration nr 180: loss=127.16291809082031\n",
      "\tIteration nr 190: loss=101.72335052490234\n",
      "\tIteration nr 200: loss=83.99574279785156\n",
      "\tIteration nr 210: loss=218.7068328857422\n",
      "\tIteration nr 220: loss=90.38179016113281\n",
      "\tIteration nr 230: loss=110.47145080566406\n",
      "\tIteration nr 240: loss=112.1072998046875\n",
      "Test loss after 1 epoch = 6533.568359375\n",
      "Epoch=2\n",
      "\tIteration nr 250: loss=134.25759887695312\n",
      "\tIteration nr 260: loss=136.7010955810547\n",
      "\tIteration nr 270: loss=90.35220336914062\n",
      "\tIteration nr 280: loss=124.00931549072266\n",
      "\tIteration nr 290: loss=78.36788177490234\n",
      "\tIteration nr 300: loss=113.69500732421875\n",
      "\tIteration nr 310: loss=72.2538833618164\n",
      "\tIteration nr 320: loss=114.8296127319336\n",
      "\tIteration nr 330: loss=87.12699127197266\n",
      "\tIteration nr 340: loss=82.8347396850586\n",
      "\tIteration nr 350: loss=108.3934555053711\n",
      "\tIteration nr 360: loss=103.75386810302734\n",
      "\tIteration nr 370: loss=102.52082824707031\n",
      "\tIteration nr 380: loss=121.58329010009766\n",
      "\tIteration nr 390: loss=83.00103759765625\n",
      "\tIteration nr 400: loss=79.90172576904297\n",
      "\tIteration nr 410: loss=62.68746566772461\n",
      "\tIteration nr 420: loss=98.64527893066406\n",
      "\tIteration nr 430: loss=95.58146667480469\n",
      "\tIteration nr 440: loss=55.9459342956543\n",
      "\tIteration nr 450: loss=89.60092163085938\n",
      "\tIteration nr 460: loss=130.44979858398438\n",
      "\tIteration nr 470: loss=97.82518768310547\n",
      "\tIteration nr 480: loss=83.66068267822266\n",
      "\tIteration nr 490: loss=122.3587875366211\n",
      "Test loss after 2 epoch = 6214.29296875\n",
      "Epoch=3\n",
      "\tIteration nr 500: loss=112.53923797607422\n",
      "\tIteration nr 510: loss=89.68285369873047\n",
      "\tIteration nr 520: loss=62.56012725830078\n",
      "\tIteration nr 530: loss=64.6843490600586\n",
      "\tIteration nr 540: loss=42.053382873535156\n",
      "\tIteration nr 550: loss=101.91260528564453\n",
      "\tIteration nr 560: loss=126.80804443359375\n",
      "\tIteration nr 570: loss=56.408477783203125\n",
      "\tIteration nr 580: loss=38.8146858215332\n",
      "\tIteration nr 590: loss=104.03484344482422\n",
      "\tIteration nr 600: loss=64.787353515625\n",
      "\tIteration nr 610: loss=131.71739196777344\n",
      "\tIteration nr 620: loss=47.308895111083984\n",
      "\tIteration nr 630: loss=89.41332244873047\n",
      "\tIteration nr 640: loss=84.91072082519531\n",
      "\tIteration nr 650: loss=43.668548583984375\n",
      "\tIteration nr 660: loss=49.36409378051758\n",
      "\tIteration nr 670: loss=115.42561340332031\n",
      "\tIteration nr 680: loss=86.18041229248047\n",
      "\tIteration nr 690: loss=135.5752410888672\n",
      "\tIteration nr 700: loss=144.7644500732422\n",
      "\tIteration nr 710: loss=84.51119232177734\n",
      "\tIteration nr 720: loss=63.31782150268555\n",
      "\tIteration nr 730: loss=61.6705207824707\n",
      "Test loss after 3 epoch = 6102.3525390625\n",
      "Epoch=4\n",
      "\tIteration nr 740: loss=69.19488525390625\n",
      "\tIteration nr 750: loss=79.96114349365234\n",
      "\tIteration nr 760: loss=100.65930938720703\n",
      "\tIteration nr 770: loss=80.343994140625\n",
      "\tIteration nr 780: loss=94.30252838134766\n",
      "\tIteration nr 790: loss=105.2508316040039\n",
      "\tIteration nr 800: loss=64.0412826538086\n",
      "\tIteration nr 810: loss=168.61891174316406\n",
      "\tIteration nr 820: loss=73.14439392089844\n",
      "\tIteration nr 830: loss=112.0267333984375\n",
      "\tIteration nr 840: loss=99.8061294555664\n",
      "\tIteration nr 850: loss=67.66510009765625\n",
      "\tIteration nr 860: loss=51.610939025878906\n",
      "\tIteration nr 870: loss=107.7225341796875\n",
      "\tIteration nr 880: loss=150.38201904296875\n",
      "\tIteration nr 890: loss=157.6314697265625\n",
      "\tIteration nr 900: loss=126.64949798583984\n",
      "\tIteration nr 910: loss=61.37150955200195\n",
      "\tIteration nr 920: loss=115.8213882446289\n",
      "\tIteration nr 930: loss=118.99662017822266\n",
      "\tIteration nr 940: loss=101.12743377685547\n",
      "\tIteration nr 950: loss=130.94091796875\n",
      "\tIteration nr 960: loss=116.687255859375\n",
      "\tIteration nr 970: loss=94.21327209472656\n",
      "\tIteration nr 980: loss=64.11616516113281\n",
      "Test loss after 4 epoch = 6095.54052734375\n",
      "Epoch=5\n",
      "\tIteration nr 990: loss=36.515625\n",
      "\tIteration nr 1000: loss=81.9702377319336\n",
      "\tIteration nr 1010: loss=68.97032928466797\n",
      "\tIteration nr 1020: loss=91.79651641845703\n",
      "\tIteration nr 1030: loss=80.08757019042969\n",
      "\tIteration nr 1040: loss=91.46468353271484\n",
      "\tIteration nr 1050: loss=70.18529510498047\n",
      "\tIteration nr 1060: loss=54.3996467590332\n",
      "\tIteration nr 1070: loss=111.50067138671875\n",
      "\tIteration nr 1080: loss=73.91368103027344\n",
      "\tIteration nr 1090: loss=74.45266723632812\n",
      "\tIteration nr 1100: loss=87.25567626953125\n",
      "\tIteration nr 1110: loss=79.92510223388672\n",
      "\tIteration nr 1120: loss=73.83697509765625\n",
      "\tIteration nr 1130: loss=46.314517974853516\n",
      "\tIteration nr 1140: loss=104.71715545654297\n",
      "\tIteration nr 1150: loss=61.666839599609375\n",
      "\tIteration nr 1160: loss=109.31744384765625\n",
      "\tIteration nr 1170: loss=61.51203536987305\n",
      "\tIteration nr 1180: loss=69.30733489990234\n",
      "\tIteration nr 1190: loss=146.2826385498047\n",
      "\tIteration nr 1200: loss=81.1213150024414\n",
      "\tIteration nr 1210: loss=111.40299224853516\n",
      "\tIteration nr 1220: loss=38.07499313354492\n",
      "\tIteration nr 1230: loss=44.39254379272461\n",
      "Test loss after 5 epoch = 6081.53125\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "def reshape_input_tensor(input_tensor):\n",
    "    B, H, W, C = input_tensor.shape\n",
    "    return input_tensor.reshape((B, C, H, W)).float()\n",
    "\n",
    "def train_single_epoch(model, dataloader, epoch, optimizer, criterion,  device):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for i, (input_tensor, target_tensor) in enumerate(dataloader):\n",
    "        iteration = (train_size // batch_size) * epoch + i\n",
    "\n",
    "        input_tensor = reshape_input_tensor(input_tensor.to(device))\n",
    "        target_tensor = target_tensor.to(device)\n",
    "\n",
    "        prediction_tensor = model(input_tensor)\n",
    "        prediction_tensor = torch.squeeze(prediction_tensor)\n",
    "\n",
    "        loss = criterion(prediction_tensor, target_tensor.float())\n",
    "        if (iteration + 1) % 10 == 0:\n",
    "            print(f\"\\tIteration nr {iteration + 1}: loss={loss}\")\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.detach())\n",
    "    return losses\n",
    "\n",
    "def evaluate_on_test_set(model, dataloader, criterion,  device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0\n",
    "        for i, (input_tensor, target_tensor) in enumerate(dataloader):\n",
    "            input_tensor = reshape_input_tensor(input_tensor.to(device))\n",
    "            target_tensor = target_tensor.to(device)\n",
    "\n",
    "            prediction_tensor = model(input_tensor)\n",
    "            prediction_tensor = torch.squeeze(prediction_tensor)\n",
    "\n",
    "            loss = criterion(prediction_tensor, target_tensor.float())\n",
    "            # TODO: accuracy etc. as well maybe? or just after whole training?\n",
    "\n",
    "            test_loss += loss\n",
    "    return test_loss\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Working on {device} device\")\n",
    "model = AiaUNet(in_channels=3, out_channels=1).to(device)\n",
    "# model.load_state_dict(torch.load(\"PATH\")).to(device) # TODO: uncomment when you want to load model\n",
    "optimizer = Adam(model.parameters(), lr=0.001, betas=(0.5, 0.999))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_epoch_losses = []\n",
    "test_epoch_losses = []\n",
    "for epoch in range(0, 5):\n",
    "    print(f\"Epoch={epoch+1}\")\n",
    "\n",
    "    new_train_losses = train_single_epoch(model, train_loader, epoch, optimizer, criterion, device)\n",
    "    train_epoch_losses.append(new_train_losses)\n",
    "\n",
    "    new_test_loss = evaluate_on_test_set(model, test_loader, criterion, device)\n",
    "    print(f\"Test loss after {epoch+1} epoch = {new_test_loss}\")\n",
    "    test_epoch_losses.append(new_test_loss)\n",
    "\n",
    "    torch.save(model.state_dict(), f\"model-{epoch+1}epoch.pt\")\n",
    "\n",
    "# TODO: tune learning_rate maybe?"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T15:15:26.130422Z",
     "start_time": "2023-06-28T15:03:10.327556800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TODO: evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test losses\n",
      "6533.568359375\n",
      "6214.29296875\n",
      "6102.3525390625\n",
      "6095.54052734375\n",
      "6081.53125\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTest losses\")\n",
    "for l in test_epoch_losses:\n",
    "    print(l.item())\n",
    "# TODO: code for evaluation..."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T15:19:32.733375500Z",
     "start_time": "2023-06-28T15:19:32.722697300Z"
    }
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "83e603ff-a32e-4d90-84d9-eba8570d6e63",
   "metadata": {},
   "source": [
    "## Task 4: Small Report of your model and training\n",
    "- visualize training and test error over each epoch\n",
    "- report the evaluation metrics of the final model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
