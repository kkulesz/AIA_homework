{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5ade700e-1f9a-4268-a809-4f829ce411c8",
   "metadata": {},
   "source": [
    "# Homework 5: Scene-Dependent Image Segmentation\n",
    "\n",
    "The goal of this homework is to implement a model that seperates foreground and background objects for a specific scene.  \n",
    "We will use the highway scene from the Change Detection dataset:  \n",
    "http://jacarini.dinf.usherbrooke.ca/dataset2014#\n",
    "\n",
    "![input image](highway/input/in001600.jpg \"Title\") ![gt image](highway/groundtruth/gt001600.png \"Title\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6fb7169c",
   "metadata": {},
   "source": [
    "The groundtruth images contain 5 labels namely\n",
    "- 0 : Static\n",
    "- 50 : Hard shadow\n",
    "- 85 : Outside region of interest\n",
    "- 170 : Unknown motion (usually around moving objects, due to semi-transparency and motion blur)\n",
    "- 255 : Motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a3d58d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T16:09:11.185060400Z",
     "start_time": "2023-06-27T16:09:11.172821700Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ea8b5923-78bb-48e7-8db6-79b35b79b942",
   "metadata": {},
   "source": [
    "## Task 1: Create a custom (Pytorch) dataset\n",
    "\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
    "You need to create a class that inherets from **from torch.utils.data.Dataset** and implements two methods:\n",
    "- **def \\_\\_len\\_\\_(self)**:  returns the length of the dataset\n",
    "- **def \\_\\_getitem\\_\\_(self, idx)**: given an integer idx returns the data x,y\n",
    "    - x is the image as a float tensor of shape: $(3,H,W)$ \n",
    "    - y is the label image as a mask of shape: $(H,W)$ each pixel should contain the label 0 (background) or 1 (foreground). It is recommended to use the type torch.long\n",
    "    \n",
    "**Tips**:\n",
    "- The first 470 images are not labeled. Just ignore these images. \n",
    "- If possible load all images into memory or evene directly to GPU to increase speed.\n",
    "- You can change the resolution to fit your model or your memory\n",
    "- Add data augmentation to increase the data size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b84fd59b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T16:09:11.941172200Z",
     "start_time": "2023-06-27T16:09:11.932172300Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "def binarize(img):\n",
    "    img = img > 0\n",
    "    bin_img = torch.tensor(img, dtype = torch.long)\n",
    "    return bin_img\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, imgs_dir, targets_dir, transform=None, imgs_to_skip=469):\n",
    "        self.imgs_dir = imgs_dir\n",
    "        self.targets_dir = targets_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        # get a list of the name of the images that are in the directory:\n",
    "        #  - skip first 469 images, because they are labeled\n",
    "        #  - sort it, so we are sure input image matches target\n",
    "        self.img_file_names = list(sorted(os.listdir(imgs_dir)[imgs_to_skip:]))\n",
    "        self.target_file_names = list(sorted(os.listdir(targets_dir)[imgs_to_skip:]))\n",
    "        assert len(self.img_file_names) == len(self.target_file_names) # make sure we have the same number of images and targets\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.target_file_names)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # 1. read input image\n",
    "        img_path = os.path.join(self.imgs_dir, self.img_file_names[idx])\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n",
    "        img_tensor = torch.from_numpy(img)\n",
    "\n",
    "        # 2. read target image\n",
    "        target_path = os.path.join(self.targets_dir, self.target_file_names[idx])\n",
    "        target_img = cv2.imread(target_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        if self.transform:\n",
    "            target_img = self.transform(target_img)\n",
    "        target_tensor = target_img\n",
    "        return img_tensor, target_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd398ae9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T16:09:12.288769800Z",
     "start_time": "2023-06-27T16:09:12.272768900Z"
    }
   },
   "outputs": [],
   "source": [
    "# dataset = CustomImageDataset(imgs_dir='./highway/input', targets_dir='./highway/groundtruth', transform=binarize)\n",
    "# print(f\"Dataset size={len(dataset)}\")\n",
    "# org_img, mask_img = dataset[1220]\n",
    "# plt.imshow(org_img)\n",
    "# plt.show()\n",
    "# plt.imshow(mask_img, cmap=\"gray\")\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0e120eb7-0349-4bb0-b305-23a0f3bb5e26",
   "metadata": {},
   "source": [
    "## Task 2: Create a custom Segmentation Model\n",
    "\n",
    "- input: a batch of images $(B,3,H,W)$ \n",
    "- output: a batch of pixel-wise class predictions $(B,C,H,W)$, where $C=2$\n",
    "\n",
    "Tips:\n",
    "- It is recommended to use a Fully-Convolutional Neural Network, because it flexible to the input and output resolution.\n",
    "- Use Residual Blocks with convolutional layers.\n",
    "- Base your model on established segmentation models:\n",
    "    - U-Net: https://arxiv.org/abs/1505.04597\n",
    "    - Deeplab: https://arxiv.org/abs/1606.00915"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "        self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "class AiaUNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(AiaUNet, self).__init__()\n",
    "\n",
    "        self.inc = (DoubleConv(in_channels, 64))\n",
    "        self.down1 = (Down(64, 128))\n",
    "        self.down2 = (Down(128, 256))\n",
    "        self.down3 = (Down(256, 512))\n",
    "        self.up2 = (Up(512, 256))\n",
    "        self.up3 = (Up(256, 128))\n",
    "        self.up4 = (Up(128, 64))\n",
    "        self.outc = (OutConv(64, out_channels))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x = self.up2(x4, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        return logits"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-27T16:09:13.026346800Z",
     "start_time": "2023-06-27T16:09:13.024375300Z"
    }
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a85364b0-7010-4710-9373-94a89db8d7c5",
   "metadata": {},
   "source": [
    "## Task 3: Create a training loop\n",
    "- split data into training and test data, e.g. 80% training data and 20% test data using your custom dataset.\n",
    "- Create a Dataloader for your custom datasets \n",
    "- Define a training loop for a single epoch:\n",
    "    - forward pass\n",
    "    - Loss function, e.g. cross entropy\n",
    "    - optimizer \n",
    "    - backward pass\n",
    "    - logging\n",
    "- Define validation loop:\n",
    "    - forward pass\n",
    "    - extract binary labels, e.g. threshold or argmax for each pixel.\n",
    "    - compute evaluation metrics: Accuracy, Precision, Recall and Intersection over Union for each image"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split data test/train and create dataloader"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size = 984, number of batches in train = 31\n",
      "Test size = 247, number of batches in test = 8\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "dataset = CustomImageDataset(imgs_dir='./highway/input', targets_dir='./highway/groundtruth', transform=binarize)\n",
    "dataset_size = len(dataset)\n",
    "\n",
    "train_size_percentage = 0.8\n",
    "train_size = int(dataset_size * train_size_percentage)\n",
    "test_size = dataset_size - train_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Train size = {len(train_dataset)}, number of batches in train = {len(train_loader)}\")\n",
    "print(f\"Test size = {len(test_dataset)}, number of batches in test = {len(test_loader)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-27T16:09:14.291536700Z",
     "start_time": "2023-06-27T16:09:14.271536Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define a training loop"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "def reshape_input_tensor(input_tensor):\n",
    "    B, H, W, C = input_tensor.shape\n",
    "    return input_tensor.reshape((B, C, H, W)).float()\n",
    "\n",
    "def train_single_epoch(model, dataloader, epoch, optimizer, criterion,  device):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for i, (input_tensor, target_tensor) in enumerate(dataloader):\n",
    "        iteration = (train_size // batch_size) * epoch + i\n",
    "\n",
    "        input_tensor = reshape_input_tensor(input_tensor.to(device))\n",
    "        target_tensor = target_tensor.to(device)\n",
    "\n",
    "        prediction_tensor = model(input_tensor)\n",
    "        prediction_tensor = torch.squeeze(prediction_tensor)\n",
    "\n",
    "        loss = criterion(prediction_tensor, target_tensor.float())\n",
    "        print(f\"\\tIteration nr {iteration + 1}: loss={loss}\")\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.detach())\n",
    "    return losses\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Working on {device} device\")\n",
    "model = AiaUNet(in_channels=3, out_channels=1).to(device)\n",
    "# model.load_state_dict(torch.load(\"PATH\")).to(device) # TODO: uncomment when you want to load model\n",
    "optimizer = Adam(model.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "epoch_losses = []\n",
    "for epoch in range(0, 5):\n",
    "    print(f\"Epoch={epoch+1}\")\n",
    "    new_losses = train_single_epoch(model,train_loader, epoch, optimizer, criterion, device)\n",
    "    torch.save(model.state_dict(), f\"model-{epoch+1}epoch.pt\")\n",
    "    epoch_losses.append(new_losses)\n",
    "\n",
    "# TODO: tune learning_rate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TODO: evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO: code for evaluation..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "83e603ff-a32e-4d90-84d9-eba8570d6e63",
   "metadata": {},
   "source": [
    "## Task 4: Small Report of your model and training\n",
    "- visualize training and test error over each epoch\n",
    "- report the evaluation metrics of the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
